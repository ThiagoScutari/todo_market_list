## Relatório Final da Sprint 1 - Projeto ToDo Market & List

**Data:** [Inserir Data da Reunião]
**Status:** Módulo 1 (Lista de Compras Inteligente) Funcional e Testado com Sucesso.

---

### Arquivos Criados na Sprint 1:

*   **Modelos de Dados:**
    *   `src/models/models.py`: Contém as classes SQLAlchemy ORM para `Categoria`, `UnidadeMedida`, `Produto`, `Receita`, `ReceitaIngrediente`, `TipoLista` e `ListaItem`.
*   **Inicialização do Banco de Dados:**
    *   `setup_database.py`: Script para criar o banco de dados SQLite (`todo_market.db`), as tabelas e inserir dados iniciais essenciais (Categorias, Unidades, Tipos de Lista).
*   **Testes:**
    *   `tests/teste_insercao.py`: Script de teste para validar a inserção de produtos e a integridade das relações no banco de dados.
*   **API Flask:**
    *   `src/app.py`: Aplicação Flask que expõe as rotas `POST /item` para adicionar produtos e `GET /items` para listar produtos.
*   **Processamento NLP:**
    *   `processador_nlp.py`: Script responsável por receber texto natural, processá-lo com Gemini Lite, extrair dados em JSON e enviá-los para a API Flask.

---

### Fluxo Validado na Sprint 1:

O fluxo principal para a adição de itens à lista de compras foi implementado e testado com sucesso:

1.  **Entrada de Texto Natural:** Um comando em linguagem natural é fornecido (ex: 'Preciso comprar 3kg de costela para o churrasco').
2.  **Processamento NLP:** O script `processador_nlp.py` recebe o texto e utiliza o modelo Gemini Lite (configurado via `langchain_google_genai`) para interpretar a intenção.
    *   O prompt é cuidadosamente elaborado para solicitar uma saída JSON estrita, listando categorias válidas e instruindo sobre o tratamento de unidades e categorias ausentes.
    *   A resposta bruta do Gemini é processada para remover possíveis marcações de markdown (```json ... ```) e validada como JSON.
3.  **Extração de Dados em JSON:** O texto é convertido em um objeto JSON com as chaves `nome`, `quantidade`, `unidade` e `categoria`.
4.  **Envio para API:** O JSON extraído é enviado para a API Flask (`src/app.py`) através de uma requisição `POST` para o endpoint `/item`.
5.  **Persistência no Banco de Dados:** A API Flask recebe o JSON, busca os IDs correspondentes para categoria e unidade, cria uma nova entrada de `Produto` e a salva no banco de dados SQLite (`todo_market.db`).
6.  **Confirmação (Implícita):** A funcionalidade de consulta (`GET /items`) na API Flask permite verificar se os dados foram corretamente persistidos.

---

**Observações:**

*   A integração com o banco de dados local SQLite foi bem-sucedida.
*   A capacidade do Gemini de extrair informações estruturadas em JSON foi validada, com tratamento para garantir a formatação correta.
*   A comunicação entre o script NLP e a API Flask está operacional.

---

**Próximos Passos:**

*   Definir a estratégia de conexão entre o `n8n` (nuvem) e os scripts Python locais (API Flask, `processador_nlp.py`).
*   Desenvolver a integração com o `n8n` para orquestrar o fluxo completo.
*   Implementar a interface do bot do Telegram para interagir com o sistema.

---

**Fim do Relatório da Sprint 1.**