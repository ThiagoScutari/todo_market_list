# üìê Planejamento de Arquitetura RAG Avan√ßada (FamilyOS)

[cite_start]**Baseado em:** "Aprofundando em RAG e suas Varia√ß√µes" [cite: 1]
**Objetivo:** Implementar um pipeline de recupera√ß√£o robusto que supere as limita√ß√µes do "Naive RAG" para o Chat do FamilyOS.

---

## 1. Diagn√≥stico e Necessidade

O documento alerta que o **Naive RAG** (apenas busca vetorial simples) falha em casos de:
* [cite_start]**Recupera√ß√£o Lexical:** Quando o usu√°rio busca por IDs ou nomes exatos (ex: "Tarefa #123")[cite: 48].
* [cite_start]**Lost-in-the-Middle:** LLMs esquecem informa√ß√µes no meio de contextos longos[cite: 178].

[cite_start]**Solu√ß√£o Adotada:** **Modular RAG**  [cite_start]com **Busca H√≠brida**.

---

## 2. Arquitetura do Pipeline (Modular RAG)

[cite_start]O fluxo de dados ser√° decomposto em m√≥dulos independentes[cite: 79]:
### M√≥dulo 1: Indexa√ß√£o e Chunking (Offline)
* [cite_start]**Estrat√©gia:** Evitar "Blind Chunking" (corte cego)[cite: 49]. [cite_start]Usaremos **Semantic Chunking** ou fragmenta√ß√£o recursiva respeitando limites de frases/par√°grafos[cite: 31].
* [cite_start]**Modelo de Embedding:** Utilizar um modelo otimizado para *Retrieval* (MTEB Leaderboard), focado na m√©trica **NDCG@10**[cite: 162].

### M√≥dulo 2: Recupera√ß√£o H√≠brida (Pre-Retrieval & Retrieval)
* [cite_start]**Router (Roteador):** Um pequeno LLM classifica a inten√ß√£o[cite: 88]:
    * *Inten√ß√£o Factual:* "O que √© RAG?" -> Rota para Vector DB.
    * [cite_start]*Inten√ß√£o de Dados:* "Status da tarefa 10" -> Rota para SQL/API[cite: 91].
* **Hybrid Search:**
    * [cite_start]**Vetor (Sem√¢ntico):** ChromaDB ou FAISS para similaridade[cite: 173].
    * [cite_start]**Lexical (Palavra-chave):** BM25 para encontrar termos exatos.
* [cite_start]**Fus√£o:** Combinar resultados usando *Reciprocal Rank Fusion (RRF)*[cite: 103].

### M√≥dulo 3: P√≥s-Recupera√ß√£o (Reranking)
* [cite_start]**Problema:** O Recuperador inicial prioriza Recall (trazer tudo), mas traz ru√≠do[cite: 65].
* [cite_start]**Solu√ß√£o:** Implementar um **Cross-Encoder** (Reranker) para reordenar os Top-50 resultados e entregar apenas o Top-5 mais relevante ao LLM[cite: 69, 70].
* [cite_start]**Mitiga√ß√£o de Vi√©s:** Posicionar os chunks mais importantes no in√≠cio e no fim do prompt para evitar o problema "Lost-in-the-Middle"[cite: 186].

### M√≥dulo 4: Gera√ß√£o e Avalia√ß√£o (Self-Correction)
* [cite_start]**Corrective RAG (CRAG):** Se a recupera√ß√£o for avaliada como "Incorreta" ou "Amb√≠gua"[cite: 131, 133], o sistema deve acionar um fallback (ex: pedir clarifica√ß√£o ao usu√°rio ou buscar na web, se habilitado).

---

## 3. Stack Tecnol√≥gico Sugerido

[cite_start]Baseado na compara√ß√£o de Vector DBs[cite: 172]:

| Componente | Tecnologia Sugerida | Justificativa |
| :--- | :--- | :--- |
| **Vector DB** | **Chroma** | [cite_start]Open Source, ideal para prototipagem m√©dia e simples de usar[cite: 173]. |
| **Embedding** | **text-embedding-3-small** | (OpenAI) Bom balanceamento custo/performance MTEB. |
| **Orquestra√ß√£o** | **LangChain** | [cite_start]Framework maduro para compor esses m√≥dulos "lego"[cite: 107]. |
| **Avalia√ß√£o** | **RAGAs** | [cite_start]Framework "LLM-as-a-judge" para medir Fidelidade e Relev√¢ncia[cite: 216]. |

---

## 4. Plano de Implementa√ß√£o (Fases)

1.  **Fase 1 (MVP H√≠brido):** Implementar ChromaDB + BM25 (via LangChain EnsembleRetriever).
2.  **Fase 2 (Refinamento):** Adicionar Reranker (Cross-Encoder) no pipeline.
3.  [cite_start]**Fase 3 (Qualidade):** Configurar RAGAs para testar "Faithfulness" e "Answer Relevancy"[cite: 221, 225].

---